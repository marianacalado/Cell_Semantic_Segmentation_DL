{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto_DACO_V2-UNET_1HOT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DACO Project - Neuronal Cells segmentation\n",
        "Authors: Daniel Corona; Daniel Silva; Mariana Calado"
      ],
      "metadata": {
        "id": "2MjRh1xBE_9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rSuN_ciex-LE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57cf503-2598-4737-9891-b66cdc370fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check GPU "
      ],
      "metadata": {
        "id": "TAvWegoHHh4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "AXWDGRGzHjzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset separation by Class"
      ],
      "metadata": {
        "id": "Fzj8vgZKBHcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "from PIL import Image\n",
        "import os\n",
        "csvfile=open(r\"/content/drive/MyDrive/DACO/Datasets/train.csv\")\n",
        "\n",
        "csvreader=csv.reader(csvfile)\n",
        "ids=[]\n",
        "class_=[]\n",
        "csv=[]\n",
        "for row in csvreader:\n",
        "  csv.append(row);\n",
        "  ids.append(row[0])\n",
        "  class_.append(row[4])\n",
        "\n",
        "class_=np.array(class_).reshape(-1,1)\n",
        "ids=np.array(ids).reshape(-1,1)\n",
        "\n",
        "classes=np.concatenate([ids,class_],axis=1)\n",
        "\n",
        "\n",
        "train=os.listdir('/content/drive/MyDrive/DACO/Datasets/train')\n",
        "\n",
        "train=[x[:-4] for x in train]\n",
        "cort_ids=[classes[x][0] for x in range(classes.shape[0]) if classes[x][1]=='cort']\n",
        "astro_ids=[classes[x][0] for x in range(classes.shape[0]) if classes[x][1]=='astro']\n",
        "shsy5y_ids=[classes[x][0] for x in range(classes.shape[0]) if classes[x][1]=='shsy5y']\n",
        "cort_ids_f=[]\n",
        "astro_ids_f=[]\n",
        "shsy5y_ids_f=[]\n",
        "\n",
        "[cort_ids_f.append(n) for n in cort_ids if n not in cort_ids_f] \n",
        "[astro_ids_f.append(n) for n in astro_ids if n not in astro_ids_f] \n",
        "[shsy5y_ids_f.append(n) for n in shsy5y_ids if n not in shsy5y_ids_f] \n",
        "\n",
        "cort=np.array(['cort' for x in range(len(cort_ids_f))]).reshape(-1,1)\n",
        "astro=np.array(['astro' for x in range(len(astro_ids_f))]).reshape(-1,1)\n",
        "shsy5y=np.array(['shsy5y' for x in range(len(shsy5y_ids_f))]).reshape(-1,1)\n",
        "\n",
        "cort_ids_f=np.array(cort_ids_f).reshape(-1,1)\n",
        "astro_ids_f=np.array(astro_ids_f).reshape(-1,1)\n",
        "shsy5y_ids_f=np.array(shsy5y_ids_f).reshape(-1,1)\n",
        "\n",
        "\n",
        "cort=np.concatenate([cort_ids_f,cort],axis=1)\n",
        "astro=np.concatenate([astro_ids_f,astro],axis=1)\n",
        "shsy5y=np.concatenate([shsy5y_ids_f,shsy5y],axis=1)\n",
        "\n",
        "ids_classes=np.concatenate([cort,astro,shsy5y])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eetnneELBGva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Class"
      ],
      "metadata": {
        "id": "HW7j9idQPJdQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQk4PnDbRS4x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import skimage\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "\n",
        "root_path = '/content/drive/MyDrive/DACO/Datasets'\n",
        "\n",
        "#Class which allow iterate through images from the dataset\n",
        "class SartoriusDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms,id_classes):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.id_classes=id_classes\n",
        "        #Load all training images and masks, sorting them to ensure that they are aligned\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"train\"))))\n",
        "        self.masks = list(sorted(os.listdir(os.path.join(root, \"train_mask\"))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #Load images and masks\n",
        "        img_path = os.path.join(self.root, \"train\", self.imgs[idx])\n",
        "        mask_path = os.path.join(self.root, \"train_mask\", self.masks[idx])\n",
        "\n",
        "        #Open image and mask\n",
        "        img = io.imread(img_path)\n",
        "        #img = skimage.color.gray2rgb(img)\n",
        "        mask = io.imread(mask_path)\n",
        "        \n",
        "        zeros=np.expand_dims(np.zeros((520,704)),axis=-1)\n",
        "        ones=np.expand_dims(np.ones((520,704)),axis=-1)\n",
        "       \n",
        "        if ids_classes[idx][1]=='cort':\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            img=np.concatenate([img,ones,zeros,zeros],axis=-1)\n",
        "        if ids_classes[idx][1]=='astro':\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            img=np.concatenate([img,zeros,ones,zeros],axis=-1)\n",
        "        if ids_classes[idx][1]=='shsy5y':\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            img=np.concatenate([img,zeros,zeros,ones],axis=-1)\n",
        "        \n",
        "        if self.transforms is not None:\n",
        "            img =self.transforms(img)\n",
        "            mask = self.transforms(mask)\n",
        "        \n",
        "        \n",
        "        #return img, target\n",
        "        return img, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "#Class which allow iterate through images from the dataset\n",
        "class SartoriusTestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "\n",
        "        #Load all training images and masks, sorting them to ensure that they are aligned\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"test\"))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #Load images and masks\n",
        "        img_path = os.path.join(self.root, \"test\", self.imgs[idx])\n",
        "\n",
        "        #Open image and mask\n",
        "        img = io.imread(img_path)\n",
        "       \n",
        "        \n",
        "        ones=np.expand_dims(np.ones((520,704)),axis=-1)\n",
        "        zeros=np.expand_dims(np.zeros((520,704)),axis=-1)\n",
        "        if ids_classes[idx][1]=='cort':\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            img=np.concatenate([img,ones,zeros,zeros],axis=-1)\n",
        "        if ids_classes[idx][1]=='astro':\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            img=np.concatenate([img,zeros,ones,zeros],axis=-1)\n",
        "        if ids_classes[idx][1]=='shsy5y':\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            img=np.concatenate([img,zeros,zeros,ones],axis=-1)\n",
        "        if self.transforms is not None:\n",
        "            img =self.transforms(img)\n",
        "\n",
        "        #return img, target\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# U-Net Model"
      ],
      "metadata": {
        "id": "k24D1d9pvP7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(self,in_channels,init_features):\n",
        "        super().__init__()         \n",
        "        \n",
        "        features=init_features\n",
        "        \n",
        "        # Construct the encoder blocks\n",
        "        self.enc1 = double_conv(in_channels, features)       \n",
        "        self.enc2 =  double_conv(features, features * 2)      \n",
        "        self.enc3 = double_conv(features * 2, features * 4)       \n",
        "        self.enc4 =double_conv(features * 4, features * 8)       \n",
        "        self.bottleneck = b_conv(features * 8, features * 16)     \n",
        "        self.pool=nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Construct the decoder blocks\n",
        "        self.dec1=dec(features*8)\n",
        "        self.upconv1=upscale(features*16,features*8)\n",
        "        self.dec2=dec(features*4)\n",
        "        self.upconv2=upscale(features*8,features*4)\n",
        "        self.dec3=dec(features*2)\n",
        "        self.upconv3=upscale(features*4,features*2)\n",
        "        self.dec4=dec(features)\n",
        "        self.upconv4=upscale(features*2,features)\n",
        "        self.conv=nn.Conv2d(features,1, kernel_size=1) #out\n",
        "    \n",
        "    def forward(self,x): #x input image\n",
        "        # encoder\n",
        "        enc1 = self.enc1(x)\n",
        "        \n",
        "        enc2 = self.enc2(self.pool(enc1))\n",
        "        \n",
        "        enc3 = self.enc3(self.pool(enc2))\n",
        "        \n",
        "        enc4 = self.enc4(self.pool(enc3))\n",
        "        \n",
        "        bottleneck = self.bottleneck(self.pool(enc4))\n",
        "        \n",
        "        dec1=self.upconv1(bottleneck)\n",
        "        dec1=copy_crop(dec1,enc4)\n",
        "        dec1=self.dec1(dec1)\n",
        "        \n",
        "        dec2=self.upconv2(dec1)\n",
        "        dec2=copy_crop(dec2,enc3)\n",
        "        dec2=self.dec2(dec2)\n",
        "        \n",
        "        dec3=self.upconv3(dec2)\n",
        "        dec3=copy_crop(dec3,enc2)\n",
        "        dec3=self.dec3(dec3)\n",
        "        \n",
        "        dec4=self.upconv4(dec3)\n",
        "        dec4=copy_crop(dec4,enc1)\n",
        "        dec4=self.dec4(dec4)\n",
        "        \n",
        "        out=self.conv(dec4)\n",
        "        \n",
        "        return out\n",
        "    def to_class(output):\n",
        "        output=[1 if (x>0.5) else 0 for x in output]\n",
        "  \n",
        "        return output\n",
        "def dec(feat):\n",
        "    return nn.Sequential(\n",
        "            nn.Conv2d(feat*2,feat,kernel_size=3,padding=1,bias=False),\n",
        "            nn.BatchNorm2d(feat),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(feat,feat,kernel_size=3,padding=1,bias=False),\n",
        "            nn.BatchNorm2d(feat),\n",
        "            nn.ReLU()\n",
        "            )\n",
        "    \n",
        "def upscale (in_f,out_f): \n",
        "    return nn.ConvTranspose2d(in_f, out_f,kernel_size=2,stride=2)\n",
        "    \n",
        "def copy_crop (dec,enc): \n",
        "    return torch.cat((dec,enc),dim=1)\n",
        "\n",
        "def double_conv(in_c, out_c):\n",
        "    conv_=nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=3,padding=1,bias=False),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_c, out_c, kernel_size=3,padding=1,bias=False),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU()\n",
        "        )\n",
        "    return conv_\n",
        "\n",
        "\n",
        "\n",
        "def b_conv(in_c, out_c):\n",
        "    conv=nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=3,padding=1),\n",
        "        nn.ReLU()\n",
        "        )\n",
        "    return conv"
      ],
      "metadata": {
        "id": "FN4yf3JPvSmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "di4yyBTrvLEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "import skimage\n",
        "from skimage import io\n",
        "from skimage import transform\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "\n",
        "pil = transforms.ToPILImage()\n",
        "\n",
        "def IoU(outputs, labels):\n",
        "  intersection = np.logical_and(labels, outputs)\n",
        "  union = np.logical_or(labels, outputs)\n",
        "  iou_score = np.sum(intersection) / np.sum(union)\n",
        "\n",
        "  return iou_score\n",
        "\n",
        "def dice_score(input, target):\n",
        "    smooth = 1.\n",
        "\n",
        "    iflat = input.view(-1)\n",
        "    tflat = target.view(-1)\n",
        "    intersection = (iflat * tflat).sum()\n",
        "    \n",
        "    return 1 - ((2. * intersection + smooth) /\n",
        "              (iflat.sum() + tflat.sum() + smooth))\n",
        "\n",
        "#Path to dataset\n",
        "root_path = '/content/drive/MyDrive/DACO/Datasets'\n",
        "save_path='/content/drive/MyDrive/DACO/Results/Unet_Hot_Enc_Weight'\n",
        "#Create transforms and compose\n",
        "composed_transform = transforms.Compose([transforms.ToTensor(),transforms.Resize((512,512)) ])\n",
        "\n",
        "#Dataset settings\n",
        "dataset = SartoriusDataset(root_path, composed_transform,ids_classes)\n",
        "\n",
        "idx = [*range(len(dataset))]\n",
        "training_idx, validation_idx = train_test_split(idx, test_size = 0.2)\n",
        "\n",
        "training_sampler = SubsetRandomSampler(training_idx)\n",
        "validation_sampler = SubsetRandomSampler(validation_idx)\n",
        "\n",
        "batch_size = 2\n",
        "training_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=training_sampler, num_workers=0)\n",
        "validation_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=validation_sampler, num_workers=0)\n",
        "\n",
        "#Define model\n",
        "model = UNET(4,32)\n",
        "\n",
        "#Define a loss function\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "#Define one optimizer and scheduler for learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), 0.01 , momentum=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.5)\n",
        "#Check if GPU is available for training\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if train_on_gpu:\n",
        "  print(\"Cuda is available! Training on GPU\")\n",
        "  model.cuda()\n",
        "else:\n",
        "  print(\"Cuda isn't available! Training on CPU\")\n",
        "\n",
        "#Number of epochs\n",
        "n_epoch = 50;\n",
        "\n",
        "training_IoU = []\n",
        "training_loss = []\n",
        "\n",
        "\n",
        "validation_IoU = []\n",
        "validation_loss = []\n",
        "\n",
        "lrs = []\n",
        "min_valid_loss = 1e9\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  print(f'[Epoch: {epoch+1}]')\n",
        "\n",
        "  #Training loop\n",
        "  model.train()\n",
        "  print('Training model...')\n",
        "\n",
        "  t_loss = 0\n",
        "  t_IoU = 0\n",
        "  t_dice = 0\n",
        "\n",
        "  for i, (img,mask) in enumerate(tqdm(training_dataloader)):\n",
        "    \n",
        "    if train_on_gpu:\n",
        "      img, mask = img.cuda(), mask.cuda()\n",
        "    \n",
        "    #Reset the optimizer gradient\n",
        "    optimizer.zero_grad()\n",
        "    img=img.float()\n",
        "    #Feedforward\n",
        "    output = model(img)\n",
        "    \n",
        "    #Calculate the loss\n",
        "    loss = criterion(output, mask)\n",
        "\n",
        "    #Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    #Update the model\n",
        "    optimizer.step()\n",
        "    \n",
        "    #Save loss\n",
        "    t_loss += loss.item()\n",
        "\n",
        "    #Save IoU\n",
        "    for j in range(batch_size):\n",
        "      t_IoU += IoU(torch.round(output[j][0]).cpu().detach().numpy(),mask[j][0].cpu().detach().numpy())\n",
        "\n",
        "    #Visualize Image:\n",
        "    '''\n",
        "    out=pil(torch.round(torch.sigmoid(output[0])))\n",
        "    display(out)'''\n",
        "\n",
        "  #Validation loop\n",
        "  model.eval()\n",
        "  print('Validating model...')\n",
        "\n",
        "  v_loss = 0\n",
        "  v_IoU = 0\n",
        "  v_dice = 0\n",
        "  for i, (img,mask) in enumerate(tqdm(validation_dataloader)):\n",
        "    \n",
        "    if train_on_gpu:\n",
        "      img, mask = img.cuda(), mask.cuda()\n",
        "\n",
        "    #Feedforward\n",
        "    img=img.float()\n",
        "    output = model(img)\n",
        "    \n",
        "    #Calculate the loss\n",
        "    loss = criterion(output, mask)\n",
        "\n",
        "    #Save loss\n",
        "    v_loss += loss.item()\n",
        "\n",
        "    #Save IoU\n",
        "    for j in range(batch_size):\n",
        "      v_IoU += IoU(torch.round(output[j][0]).cpu().detach().numpy(),mask[j][0].cpu().detach().numpy())\n",
        "\n",
        "  # learning rate update every 10 epochs:\n",
        "  if (epoch%10==0): \n",
        "    scheduler.step()\n",
        "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
        "    print(f'Learning Rate Updated to {lrs[-1]}')\n",
        "  #Average and save losses and IoU metric\n",
        "  t_loss = t_loss/len(training_dataloader.sampler)\n",
        "  v_loss = v_loss/len(validation_dataloader.sampler)\n",
        "  t_IoU = t_IoU/len(training_dataloader.sampler)\n",
        "  v_IoU = v_IoU/len(validation_dataloader.sampler)\n",
        "\n",
        "\n",
        "  training_loss.append(t_loss)\n",
        "  validation_loss.append(v_loss)\n",
        "  training_IoU.append(t_IoU)\n",
        "  validation_IoU.append(v_IoU)\n",
        "\n",
        " \n",
        "\n",
        "  #Save the model state if validation loss has decreased\n",
        "  if (v_loss < min_valid_loss):\n",
        "    min_valid_loss = v_loss\n",
        "    print(\"Validation loss decreased! Saving model...\")\n",
        "    best_model=copy.deepcopy(model.state_dict())\n",
        "    torch.save(model.state_dict(),os.path.join(save_path,'model.pth'))\n",
        "   \n",
        "  \n",
        "  print(f'Training loss: {t_loss}\\tValidation loss: {v_loss}\\tTraining IoU: {t_IoU}\\tValidation IoU: {v_IoU}\\tTraining Dice: {t_dice}\\tValidation Dice: {v_dice}')\n",
        "  np.save(os.path.join(save_path,'training_loss.npz'),training_loss);\n",
        "  np.save(os.path.join(save_path,'val_loss.npz'),validation_loss);\n",
        "  np.save(os.path.join(save_path,'training_IoU.npz'),training_IoU);\n",
        "  np.save(os.path.join(save_path,'validation_IoU.npz'),validation_IoU);\n",
        "  np.save(os.path.join(save_path,'training_dice.npz'),training_dice);\n",
        "  np.save(os.path.join(save_path,'validation_dice.npz'),validation_dice);\n",
        "\n",
        "\n",
        "np.save(os.path.join(save_path,'training_loss.npz'),training_loss);\n",
        "np.save(os.path.join(save_path,'val_loss.npz'),validation_loss);\n",
        "np.save(os.path.join(save_path,'training_IoU.npz'),training_IoU);\n",
        "np.save(os.path.join(save_path,'validation_IoU.npz'),validation_IoU);\n",
        "np.save(os.path.join(save_path,'training_dice.npz'),training_dice);\n",
        "np.save(os.path.join(save_path,'validation_dice.npz'),validation_dice);\n",
        "model.load_state_dict(best_model)\n",
        "torch.save(model.state_dict(),os.path.join(save_path,'model.pth'))\n",
        "\n"
      ],
      "metadata": {
        "id": "LLeUGFG2u1fd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}